[2025-10-31T19:06:51.862+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T19:06:51.874+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T19:06:51.875+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-10-31T19:06:51.889+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T19:06:51.895+0000] {standard_task_runner.py:60} INFO - Started process 844 to run task
[2025-10-31T19:06:51.899+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpkfoj_rea']
[2025-10-31T19:06:51.901+0000] {standard_task_runner.py:88} INFO - Job 34: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T19:06:51.977+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host fe1087a1e328
[2025-10-31T19:06:52.062+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T19:06:52.064+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T19:06:52.066+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'set -e; cd /dbt; python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 29\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n| tee /tmp/dbt_vars.json > /dev/null; echo "dbt vars => $(cat /tmp/dbt_vars.json)"; dbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "$(cat /tmp/dbt_vars.json)"\'']
[2025-10-31T19:06:52.076+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T19:06:52.216+0000] {subprocess.py:93} INFO - {"ds_lagged": "2025-10-01"}
[2025-10-31T19:06:52.220+0000] {subprocess.py:93} INFO - bash: -c: line 9: syntax error near unexpected token `|'
[2025-10-31T19:06:52.228+0000] {subprocess.py:97} INFO - Command exited with return code 2
[2025-10-31T19:06:52.244+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2025-10-31T19:06:52.247+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T190651, end_date=20251031T190652
[2025-10-31T19:06:52.262+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 34 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 2.; 844)
[2025-10-31T19:06:52.274+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-10-31T19:06:52.295+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T19:39:42.379+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T19:39:42.391+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T19:39:42.392+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-10-31T19:39:42.406+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T19:39:42.412+0000] {standard_task_runner.py:60} INFO - Started process 854 to run task
[2025-10-31T19:39:42.416+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpf1lcb891']
[2025-10-31T19:39:42.418+0000] {standard_task_runner.py:88} INFO - Job 17: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T19:39:42.513+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host 3ff65ab69399
[2025-10-31T19:39:42.610+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T19:39:42.611+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T19:39:42.613+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 29\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T19:39:42.624+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T19:39:42.775+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-01"}
[2025-10-31T19:39:44.766+0000] {subprocess.py:93} INFO - 19:39:44  Running with dbt=1.10.13
[2025-10-31T19:39:45.048+0000] {subprocess.py:93} INFO - 19:39:45  Registered adapter: clickhouse=1.9.5
[2025-10-31T19:39:45.226+0000] {subprocess.py:93} INFO - 19:39:45  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T19:39:46.977+0000] {subprocess.py:93} INFO - 19:39:46  Found 3 models, 3 sources, 488 macros
[2025-10-31T19:39:46.985+0000] {subprocess.py:93} INFO - 19:39:46
[2025-10-31T19:39:46.986+0000] {subprocess.py:93} INFO - 19:39:46  Concurrency: 4 threads (target='dev')
[2025-10-31T19:39:46.989+0000] {subprocess.py:93} INFO - 19:39:46
[2025-10-31T19:39:47.314+0000] {subprocess.py:93} INFO - 19:39:47  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T19:39:47.315+0000] {subprocess.py:93} INFO - 19:39:47  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T19:39:47.810+0000] {subprocess.py:93} INFO - 19:39:47  1 of 2 OK created sql incremental model `silver`.`silver_link_transactions` .... [OK in 0.49s]
[2025-10-31T19:39:47.881+0000] {subprocess.py:93} INFO - 19:39:47  2 of 2 OK created sql incremental model `silver`.`silver_payments` ............. [OK in 0.56s]
[2025-10-31T19:39:47.890+0000] {subprocess.py:93} INFO - 19:39:47
[2025-10-31T19:39:47.891+0000] {subprocess.py:93} INFO - 19:39:47  Finished running 2 incremental models in 0 hours 0 minutes and 0.90 seconds (0.90s).
[2025-10-31T19:39:47.958+0000] {subprocess.py:93} INFO - 19:39:47
[2025-10-31T19:39:47.959+0000] {subprocess.py:93} INFO - 19:39:47  Completed successfully
[2025-10-31T19:39:47.961+0000] {subprocess.py:93} INFO - 19:39:47
[2025-10-31T19:39:47.963+0000] {subprocess.py:93} INFO - 19:39:47  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T19:39:48.862+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-10-31T19:39:48.911+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T193942, end_date=20251031T193948
[2025-10-31T19:39:48.963+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-10-31T19:39:48.977+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T20:06:30.186+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T20:06:30.197+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T20:06:30.198+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-10-31T20:06:30.214+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T20:06:30.221+0000] {standard_task_runner.py:60} INFO - Started process 440 to run task
[2025-10-31T20:06:30.225+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpo3awqfzx']
[2025-10-31T20:06:30.228+0000] {standard_task_runner.py:88} INFO - Job 15: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T20:06:30.315+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host c2d20b09a38d
[2025-10-31T20:06:30.416+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T20:06:30.418+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T20:06:30.421+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 29\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T20:06:30.434+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T20:06:30.561+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-01"}
[2025-10-31T20:06:32.025+0000] {subprocess.py:93} INFO - 20:06:32  Running with dbt=1.10.13
[2025-10-31T20:06:32.285+0000] {subprocess.py:93} INFO - 20:06:32  Registered adapter: clickhouse=1.9.5
[2025-10-31T20:06:32.451+0000] {subprocess.py:93} INFO - 20:06:32  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T20:06:33.842+0000] {subprocess.py:93} INFO - 20:06:33  Found 3 models, 3 sources, 488 macros
[2025-10-31T20:06:33.848+0000] {subprocess.py:93} INFO - 20:06:33
[2025-10-31T20:06:33.849+0000] {subprocess.py:93} INFO - 20:06:33  Concurrency: 4 threads (target='dev')
[2025-10-31T20:06:33.851+0000] {subprocess.py:93} INFO - 20:06:33
[2025-10-31T20:06:34.167+0000] {subprocess.py:93} INFO - 20:06:34  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T20:06:34.170+0000] {subprocess.py:93} INFO - 20:06:34  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T20:06:34.611+0000] {subprocess.py:93} INFO - 20:06:34  1 of 2 OK created sql incremental model `silver`.`silver_link_transactions` .... [OK in 0.43s]
[2025-10-31T20:06:34.648+0000] {subprocess.py:93} INFO - 20:06:34  2 of 2 OK created sql incremental model `silver`.`silver_payments` ............. [OK in 0.47s]
[2025-10-31T20:06:34.662+0000] {subprocess.py:93} INFO - 20:06:34
[2025-10-31T20:06:34.666+0000] {subprocess.py:93} INFO - 20:06:34  Finished running 2 incremental models in 0 hours 0 minutes and 0.81 seconds (0.81s).
[2025-10-31T20:06:34.744+0000] {subprocess.py:93} INFO - 20:06:34
[2025-10-31T20:06:34.747+0000] {subprocess.py:93} INFO - 20:06:34  Completed successfully
[2025-10-31T20:06:34.752+0000] {subprocess.py:93} INFO - 20:06:34
[2025-10-31T20:06:34.756+0000] {subprocess.py:93} INFO - 20:06:34  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T20:06:35.565+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-10-31T20:06:35.601+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T200630, end_date=20251031T200635
[2025-10-31T20:06:35.627+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-10-31T20:06:35.646+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T20:14:14.186+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T20:14:14.197+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T20:14:14.199+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-10-31T20:14:14.216+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T20:14:14.224+0000] {standard_task_runner.py:60} INFO - Started process 332 to run task
[2025-10-31T20:14:14.229+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmp1150rpsg']
[2025-10-31T20:14:14.234+0000] {standard_task_runner.py:88} INFO - Job 9: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T20:14:14.330+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host ee75c7088485
[2025-10-31T20:14:14.454+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T20:14:14.455+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T20:14:14.456+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 29\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T20:14:14.468+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T20:14:14.629+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-01"}
[2025-10-31T20:14:16.325+0000] {subprocess.py:93} INFO - 20:14:16  Running with dbt=1.10.13
[2025-10-31T20:14:16.644+0000] {subprocess.py:93} INFO - 20:14:16  Registered adapter: clickhouse=1.9.5
[2025-10-31T20:14:16.990+0000] {subprocess.py:93} INFO - 20:14:16  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T20:14:18.679+0000] {subprocess.py:93} INFO - 20:14:18  Found 3 models, 3 sources, 488 macros
[2025-10-31T20:14:18.684+0000] {subprocess.py:93} INFO - 20:14:18
[2025-10-31T20:14:18.685+0000] {subprocess.py:93} INFO - 20:14:18  Concurrency: 4 threads (target='dev')
[2025-10-31T20:14:18.686+0000] {subprocess.py:93} INFO - 20:14:18
[2025-10-31T20:14:19.106+0000] {subprocess.py:93} INFO - 20:14:19  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T20:14:19.113+0000] {subprocess.py:93} INFO - 20:14:19  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T20:14:19.494+0000] {subprocess.py:93} INFO - 20:14:19  1 of 2 OK created sql incremental model `silver`.`silver_link_transactions` .... [OK in 0.38s]
[2025-10-31T20:14:19.526+0000] {subprocess.py:93} INFO - 20:14:19  2 of 2 OK created sql incremental model `silver`.`silver_payments` ............. [OK in 0.41s]
[2025-10-31T20:14:19.534+0000] {subprocess.py:93} INFO - 20:14:19
[2025-10-31T20:14:19.535+0000] {subprocess.py:93} INFO - 20:14:19  Finished running 2 incremental models in 0 hours 0 minutes and 0.85 seconds (0.85s).
[2025-10-31T20:14:19.674+0000] {subprocess.py:93} INFO - 20:14:19
[2025-10-31T20:14:19.675+0000] {subprocess.py:93} INFO - 20:14:19  Completed successfully
[2025-10-31T20:14:19.676+0000] {subprocess.py:93} INFO - 20:14:19
[2025-10-31T20:14:19.677+0000] {subprocess.py:93} INFO - 20:14:19  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T20:14:20.567+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-10-31T20:14:20.596+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T201414, end_date=20251031T201420
[2025-10-31T20:14:20.629+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-10-31T20:14:20.650+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T20:32:01.040+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T20:32:01.053+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T20:32:01.054+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-10-31T20:32:01.070+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T20:32:01.074+0000] {standard_task_runner.py:60} INFO - Started process 298 to run task
[2025-10-31T20:32:01.079+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpokcm4n_k']
[2025-10-31T20:32:01.081+0000] {standard_task_runner.py:88} INFO - Job 9: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T20:32:01.158+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host f865f80ec1e7
[2025-10-31T20:32:01.248+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T20:32:01.250+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T20:32:01.251+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 29\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T20:32:01.267+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T20:32:01.429+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-01"}
[2025-10-31T20:32:03.177+0000] {subprocess.py:93} INFO - 20:32:03  Running with dbt=1.10.13
[2025-10-31T20:32:03.436+0000] {subprocess.py:93} INFO - 20:32:03  Registered adapter: clickhouse=1.9.5
[2025-10-31T20:32:03.601+0000] {subprocess.py:93} INFO - 20:32:03  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T20:32:04.966+0000] {subprocess.py:93} INFO - 20:32:04  Found 3 models, 3 sources, 488 macros
[2025-10-31T20:32:04.969+0000] {subprocess.py:93} INFO - 20:32:04
[2025-10-31T20:32:04.970+0000] {subprocess.py:93} INFO - 20:32:04  Concurrency: 4 threads (target='dev')
[2025-10-31T20:32:04.971+0000] {subprocess.py:93} INFO - 20:32:04
[2025-10-31T20:32:05.251+0000] {subprocess.py:93} INFO - 20:32:05  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T20:32:05.252+0000] {subprocess.py:93} INFO - 20:32:05  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T20:32:05.572+0000] {subprocess.py:93} INFO - 20:32:05  1 of 2 OK created sql incremental model `silver`.`silver_link_transactions` .... [OK in 0.31s]
[2025-10-31T20:32:05.609+0000] {subprocess.py:93} INFO - 20:32:05  2 of 2 OK created sql incremental model `silver`.`silver_payments` ............. [OK in 0.35s]
[2025-10-31T20:32:05.619+0000] {subprocess.py:93} INFO - 20:32:05
[2025-10-31T20:32:05.620+0000] {subprocess.py:93} INFO - 20:32:05  Finished running 2 incremental models in 0 hours 0 minutes and 0.65 seconds (0.65s).
[2025-10-31T20:32:05.773+0000] {subprocess.py:93} INFO - 20:32:05
[2025-10-31T20:32:05.774+0000] {subprocess.py:93} INFO - 20:32:05  Completed successfully
[2025-10-31T20:32:05.776+0000] {subprocess.py:93} INFO - 20:32:05
[2025-10-31T20:32:05.777+0000] {subprocess.py:93} INFO - 20:32:05  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T20:32:06.657+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-10-31T20:32:06.688+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T203201, end_date=20251031T203206
[2025-10-31T20:32:06.727+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-10-31T20:32:06.744+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T21:11:02.516+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T21:11:02.525+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T21:11:02.526+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-10-31T21:11:02.541+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T21:11:02.547+0000] {standard_task_runner.py:60} INFO - Started process 805 to run task
[2025-10-31T21:11:02.551+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpp8ay29sz']
[2025-10-31T21:11:02.555+0000] {standard_task_runner.py:88} INFO - Job 25: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T21:11:02.642+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host c45a3ec2f76e
[2025-10-31T21:11:02.742+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T21:11:02.744+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T21:11:02.746+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 29\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T21:11:02.756+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T21:11:02.883+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-01"}
[2025-10-31T21:11:04.436+0000] {subprocess.py:93} INFO - 21:11:04  Running with dbt=1.10.13
[2025-10-31T21:11:04.671+0000] {subprocess.py:93} INFO - 21:11:04  Registered adapter: clickhouse=1.9.5
[2025-10-31T21:11:04.841+0000] {subprocess.py:93} INFO - 21:11:04  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T21:11:06.475+0000] {subprocess.py:93} INFO - 21:11:06  Found 3 models, 3 sources, 488 macros
[2025-10-31T21:11:06.480+0000] {subprocess.py:93} INFO - 21:11:06
[2025-10-31T21:11:06.481+0000] {subprocess.py:93} INFO - 21:11:06  Concurrency: 4 threads (target='dev')
[2025-10-31T21:11:06.483+0000] {subprocess.py:93} INFO - 21:11:06
[2025-10-31T21:11:06.783+0000] {subprocess.py:93} INFO - 21:11:06  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T21:11:06.786+0000] {subprocess.py:93} INFO - 21:11:06  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T21:11:06.960+0000] {subprocess.py:93} INFO - 21:11:06  1 of 2 ERROR creating sql incremental model `silver`.`silver_link_transactions`  [ERROR in 0.17s]
[2025-10-31T21:11:07.287+0000] {subprocess.py:93} INFO - 21:11:07  2 of 2 OK created sql incremental model `silver`.`silver_payments` ............. [OK in 0.49s]
[2025-10-31T21:11:07.298+0000] {subprocess.py:93} INFO - 21:11:07
[2025-10-31T21:11:07.299+0000] {subprocess.py:93} INFO - 21:11:07  Finished running 2 incremental models in 0 hours 0 minutes and 0.81 seconds (0.81s).
[2025-10-31T21:11:07.459+0000] {subprocess.py:93} INFO - 21:11:07
[2025-10-31T21:11:07.460+0000] {subprocess.py:93} INFO - 21:11:07  Completed with 1 error, 0 partial successes, and 0 warnings:
[2025-10-31T21:11:07.461+0000] {subprocess.py:93} INFO - 21:11:07
[2025-10-31T21:11:07.463+0000] {subprocess.py:93} INFO - 21:11:07  Failure in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-10-31T21:11:07.465+0000] {subprocess.py:93} INFO - 21:11:07    Database Error in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-10-31T21:11:07.466+0000] {subprocess.py:93} INFO -   Code: 60.
[2025-10-31T21:11:07.467+0000] {subprocess.py:93} INFO -   DB::Exception: Could not find table: silver_link_transactions. Stack trace:
[2025-10-31T21:11:07.468+0000] {subprocess.py:93} INFO - 
[2025-10-31T21:11:07.468+0000] {subprocess.py:93} INFO -   0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
[2025-10-31T21:11:07.469+0000] {subprocess.py:93} INFO -   1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
[2025-10-31T21:11:07.469+0000] {subprocess.py:93} INFO -   2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
[2025-10-31T21:11:07.470+0000] {subprocess.py:93} INFO -   3. DB::Exception::Exception<String&>(int, FormatStringHelperImpl<std::type_identity<String&>::type>, String&) @ 0x000000000cb04dab
[2025-10-31T21:11:07.470+0000] {subprocess.py:93} INFO -   4. DB::InterpreterAlterQuery::executeToTable(DB::ASTAlterQuery const&) @ 0x00000000182ce3bf
[2025-10-31T21:11:07.471+0000] {subprocess.py:93} INFO -   5. DB::InterpreterAlterQuery::execute() @ 0x00000000182c938d
[2025-10-31T21:11:07.471+0000] {subprocess.py:93} INFO -   6. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
[2025-10-31T21:11:07.472+0000] {subprocess.py:93} INFO -   7. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
[2025-10-31T21:11:07.472+0000] {subprocess.py:93} INFO -   8. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
[2025-10-31T21:11:07.473+0000] {subprocess.py:93} INFO -   9. DB::TCPHandler::run() @ 0x0000000019e4f119
[2025-10-31T21:11:07.474+0000] {subprocess.py:93} INFO -   10. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
[2025-10-31T21:11:07.474+0000] {subprocess.py:93} INFO -   11. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
[2025-10-31T21:11:07.474+0000] {subprocess.py:93} INFO -   12. Poco::PooledThread::run() @ 0x000000001ef15b87
[2025-10-31T21:11:07.475+0000] {subprocess.py:93} INFO -   13. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
[2025-10-31T21:11:07.475+0000] {subprocess.py:93} INFO -   14. ? @ 0x0000000000094ac3
[2025-10-31T21:11:07.476+0000] {subprocess.py:93} INFO -   15. ? @ 0x0000000000125a74
[2025-10-31T21:11:07.476+0000] {subprocess.py:93} INFO - 21:11:07
[2025-10-31T21:11:07.477+0000] {subprocess.py:93} INFO - 21:11:07    compiled code at target/compiled/ck_project/models/silver/silver_link_transactions.sql
[2025-10-31T21:11:07.477+0000] {subprocess.py:93} INFO - 21:11:07
[2025-10-31T21:11:07.477+0000] {subprocess.py:93} INFO - 21:11:07  Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T21:11:08.401+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-10-31T21:11:08.415+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-10-31T21:11:08.418+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T211102, end_date=20251031T211108
[2025-10-31T21:11:08.431+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 25 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 1.; 805)
[2025-10-31T21:11:08.451+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-10-31T21:11:08.469+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T22:00:24.365+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:00:24.376+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:00:24.377+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-10-31T22:00:24.391+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T22:00:24.399+0000] {standard_task_runner.py:60} INFO - Started process 364 to run task
[2025-10-31T22:00:24.404+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpeqsjcyrj']
[2025-10-31T22:00:24.407+0000] {standard_task_runner.py:88} INFO - Job 14: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T22:00:24.589+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host 9dbfb6fb81d8
[2025-10-31T22:00:24.723+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T22:00:24.725+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T22:00:24.727+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 0\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T22:00:24.744+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T22:00:24.916+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-30"}
[2025-10-31T22:00:26.612+0000] {subprocess.py:93} INFO - 22:00:26  Running with dbt=1.10.13
[2025-10-31T22:00:26.892+0000] {subprocess.py:93} INFO - 22:00:26  Registered adapter: clickhouse=1.9.5
[2025-10-31T22:00:27.060+0000] {subprocess.py:93} INFO - 22:00:27  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T22:00:28.942+0000] {subprocess.py:93} INFO - 22:00:28  Found 3 models, 3 sources, 488 macros
[2025-10-31T22:00:28.948+0000] {subprocess.py:93} INFO - 22:00:28
[2025-10-31T22:00:28.949+0000] {subprocess.py:93} INFO - 22:00:28  Concurrency: 4 threads (target='dev')
[2025-10-31T22:00:28.951+0000] {subprocess.py:93} INFO - 22:00:28
[2025-10-31T22:00:29.247+0000] {subprocess.py:93} INFO - 22:00:29  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T22:00:29.249+0000] {subprocess.py:93} INFO - 22:00:29  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T22:00:29.580+0000] {subprocess.py:93} INFO - 22:00:29  1 of 2 OK created sql incremental model `silver`.`silver_link_transactions` .... [OK in 0.33s]
[2025-10-31T22:00:29.593+0000] {subprocess.py:93} INFO - 22:00:29  2 of 2 ERROR creating sql incremental model `silver`.`silver_payments` ......... [ERROR in 0.34s]
[2025-10-31T22:00:29.603+0000] {subprocess.py:93} INFO - 22:00:29
[2025-10-31T22:00:29.604+0000] {subprocess.py:93} INFO - 22:00:29  Finished running 2 incremental models in 0 hours 0 minutes and 0.65 seconds (0.65s).
[2025-10-31T22:00:29.748+0000] {subprocess.py:93} INFO - 22:00:29
[2025-10-31T22:00:29.749+0000] {subprocess.py:93} INFO - 22:00:29  Completed with 1 error, 0 partial successes, and 0 warnings:
[2025-10-31T22:00:29.750+0000] {subprocess.py:93} INFO - 22:00:29
[2025-10-31T22:00:29.753+0000] {subprocess.py:93} INFO - 22:00:29  Failure in model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T22:00:29.755+0000] {subprocess.py:93} INFO - 22:00:29    Database Error in model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T22:00:29.756+0000] {subprocess.py:93} INFO -   Code: 60.
[2025-10-31T22:00:29.757+0000] {subprocess.py:93} INFO -   DB::Exception: Unknown table expression identifier 'bronze.payments' in scope  raw. Stack trace:
[2025-10-31T22:00:29.757+0000] {subprocess.py:93} INFO - 
[2025-10-31T22:00:29.758+0000] {subprocess.py:93} INFO -   0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
[2025-10-31T22:00:29.758+0000] {subprocess.py:93} INFO -   1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
[2025-10-31T22:00:29.759+0000] {subprocess.py:93} INFO -   2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
[2025-10-31T22:00:29.759+0000] {subprocess.py:93} INFO -   3. DB::Exception::Exception<String const&, String>(int, FormatStringHelperImpl<std::type_identity<String const&>::type, std::type_identity<String>::type>, String const&, String&&) @ 0x000000000db773ab
[2025-10-31T22:00:29.760+0000] {subprocess.py:93} INFO -   4. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x0000000017830745
[2025-10-31T22:00:29.760+0000] {subprocess.py:93} INFO -   5. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x0000000017837221
[2025-10-31T22:00:29.761+0000] {subprocess.py:93} INFO -   6. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785ae58
[2025-10-31T22:00:29.761+0000] {subprocess.py:93} INFO -   7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
[2025-10-31T22:00:29.761+0000] {subprocess.py:93} INFO -   8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x0000000017837221
[2025-10-31T22:00:29.762+0000] {subprocess.py:93} INFO -   9. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785ae58
[2025-10-31T22:00:29.762+0000] {subprocess.py:93} INFO -   10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
[2025-10-31T22:00:29.763+0000] {subprocess.py:93} INFO -   11. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
[2025-10-31T22:00:29.763+0000] {subprocess.py:93} INFO -   12. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
[2025-10-31T22:00:29.764+0000] {subprocess.py:93} INFO -   13. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
[2025-10-31T22:00:29.764+0000] {subprocess.py:93} INFO -   14. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
[2025-10-31T22:00:29.765+0000] {subprocess.py:93} INFO -   15. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
[2025-10-31T22:00:29.765+0000] {subprocess.py:93} INFO -   16. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
[2025-10-31T22:00:29.766+0000] {subprocess.py:93} INFO -   17. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
[2025-10-31T22:00:29.766+0000] {subprocess.py:93} INFO -   18. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
[2025-10-31T22:00:29.767+0000] {subprocess.py:93} INFO -   19. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
[2025-10-31T22:00:29.767+0000] {subprocess.py:93} INFO -   20. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
[2025-10-31T22:00:29.768+0000] {subprocess.py:93} INFO -   21. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
[2025-10-31T22:00:29.768+0000] {subprocess.py:93} INFO -   22. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
[2025-10-31T22:00:29.769+0000] {subprocess.py:93} INFO -   23. DB::TCPHandler::run() @ 0x0000000019e4f119
[2025-10-31T22:00:29.769+0000] {subprocess.py:93} INFO -   24. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
[2025-10-31T22:00:29.770+0000] {subprocess.py:93} INFO -   25. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
[2025-10-31T22:00:29.770+0000] {subprocess.py:93} INFO -   26. Poco::PooledThread::run() @ 0x000000001ef15b87
[2025-10-31T22:00:29.771+0000] {subprocess.py:93} INFO -   27. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
[2025-10-31T22:00:29.772+0000] {subprocess.py:93} INFO -   28. ? @ 0x0000000000094ac3
[2025-10-31T22:00:29.772+0000] {subprocess.py:93} INFO -   29. ? @ 0x0000000000125a74
[2025-10-31T22:00:29.773+0000] {subprocess.py:93} INFO - 22:00:29
[2025-10-31T22:00:29.773+0000] {subprocess.py:93} INFO - 22:00:29    compiled code at target/compiled/ck_project/models/silver/silver_payments.sql
[2025-10-31T22:00:29.774+0000] {subprocess.py:93} INFO - 22:00:29
[2025-10-31T22:00:29.774+0000] {subprocess.py:93} INFO - 22:00:29  Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T22:00:30.995+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-10-31T22:00:31.017+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-10-31T22:00:31.023+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T220024, end_date=20251031T220031
[2025-10-31T22:00:31.063+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 14 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 1.; 364)
[2025-10-31T22:00:31.078+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-10-31T22:00:31.105+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T22:13:40.848+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:13:40.859+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:13:40.861+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-10-31T22:13:40.882+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T22:13:40.889+0000] {standard_task_runner.py:60} INFO - Started process 310 to run task
[2025-10-31T22:13:40.896+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpe_l1vztm']
[2025-10-31T22:13:40.900+0000] {standard_task_runner.py:88} INFO - Job 12: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T22:13:41.006+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host 68d81e27198f
[2025-10-31T22:13:41.150+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T22:13:41.152+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T22:13:41.154+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'set -e; cd /dbt; DBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 0\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n); echo "dbt vars => ${DBT_VARS}"; dbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\'']
[2025-10-31T22:13:41.170+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T22:13:41.361+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-30"}
[2025-10-31T22:13:43.868+0000] {subprocess.py:93} INFO - 22:13:43  Running with dbt=1.10.13
[2025-10-31T22:13:44.291+0000] {subprocess.py:93} INFO - 22:13:44  Registered adapter: clickhouse=1.9.5
[2025-10-31T22:13:44.546+0000] {subprocess.py:93} INFO - 22:13:44  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T22:13:47.197+0000] {subprocess.py:93} INFO - 22:13:47  Found 3 models, 3 sources, 488 macros
[2025-10-31T22:13:47.206+0000] {subprocess.py:93} INFO - 22:13:47
[2025-10-31T22:13:47.207+0000] {subprocess.py:93} INFO - 22:13:47  Concurrency: 4 threads (target='dev')
[2025-10-31T22:13:47.208+0000] {subprocess.py:93} INFO - 22:13:47
[2025-10-31T22:13:47.771+0000] {subprocess.py:93} INFO - 22:13:47  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T22:13:47.773+0000] {subprocess.py:93} INFO - 22:13:47  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T22:13:48.069+0000] {subprocess.py:93} INFO - 22:13:48  2 of 2 ERROR creating sql incremental model `silver`.`silver_payments` ......... [ERROR in 0.29s]
[2025-10-31T22:13:48.250+0000] {subprocess.py:93} INFO - 22:13:48  1 of 2 OK created sql incremental model `silver`.`silver_link_transactions` .... [OK in 0.47s]
[2025-10-31T22:13:48.262+0000] {subprocess.py:93} INFO - 22:13:48
[2025-10-31T22:13:48.264+0000] {subprocess.py:93} INFO - 22:13:48  Finished running 2 incremental models in 0 hours 0 minutes and 1.05 seconds (1.05s).
[2025-10-31T22:13:48.344+0000] {subprocess.py:93} INFO - 22:13:48
[2025-10-31T22:13:48.346+0000] {subprocess.py:93} INFO - 22:13:48  Completed with 1 error, 0 partial successes, and 0 warnings:
[2025-10-31T22:13:48.348+0000] {subprocess.py:93} INFO - 22:13:48
[2025-10-31T22:13:48.350+0000] {subprocess.py:93} INFO - 22:13:48  Failure in model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T22:13:48.352+0000] {subprocess.py:93} INFO - 22:13:48    Database Error in model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T22:13:48.353+0000] {subprocess.py:93} INFO -   Code: 60.
[2025-10-31T22:13:48.354+0000] {subprocess.py:93} INFO -   DB::Exception: Unknown table expression identifier 'bronze.payments' in scope  raw. Stack trace:
[2025-10-31T22:13:48.354+0000] {subprocess.py:93} INFO - 
[2025-10-31T22:13:48.355+0000] {subprocess.py:93} INFO -   0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
[2025-10-31T22:13:48.356+0000] {subprocess.py:93} INFO -   1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
[2025-10-31T22:13:48.356+0000] {subprocess.py:93} INFO -   2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
[2025-10-31T22:13:48.357+0000] {subprocess.py:93} INFO -   3. DB::Exception::Exception<String const&, String>(int, FormatStringHelperImpl<std::type_identity<String const&>::type, std::type_identity<String>::type>, String const&, String&&) @ 0x000000000db773ab
[2025-10-31T22:13:48.357+0000] {subprocess.py:93} INFO -   4. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x0000000017830745
[2025-10-31T22:13:48.358+0000] {subprocess.py:93} INFO -   5. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x0000000017837221
[2025-10-31T22:13:48.359+0000] {subprocess.py:93} INFO -   6. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785ae58
[2025-10-31T22:13:48.360+0000] {subprocess.py:93} INFO -   7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
[2025-10-31T22:13:48.360+0000] {subprocess.py:93} INFO -   8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x0000000017837221
[2025-10-31T22:13:48.361+0000] {subprocess.py:93} INFO -   9. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785ae58
[2025-10-31T22:13:48.361+0000] {subprocess.py:93} INFO -   10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
[2025-10-31T22:13:48.362+0000] {subprocess.py:93} INFO -   11. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
[2025-10-31T22:13:48.362+0000] {subprocess.py:93} INFO -   12. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
[2025-10-31T22:13:48.363+0000] {subprocess.py:93} INFO -   13. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
[2025-10-31T22:13:48.363+0000] {subprocess.py:93} INFO -   14. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
[2025-10-31T22:13:48.364+0000] {subprocess.py:93} INFO -   15. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
[2025-10-31T22:13:48.365+0000] {subprocess.py:93} INFO -   16. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
[2025-10-31T22:13:48.365+0000] {subprocess.py:93} INFO -   17. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
[2025-10-31T22:13:48.366+0000] {subprocess.py:93} INFO -   18. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
[2025-10-31T22:13:48.366+0000] {subprocess.py:93} INFO -   19. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
[2025-10-31T22:13:48.367+0000] {subprocess.py:93} INFO -   20. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
[2025-10-31T22:13:48.367+0000] {subprocess.py:93} INFO -   21. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
[2025-10-31T22:13:48.368+0000] {subprocess.py:93} INFO -   22. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
[2025-10-31T22:13:48.369+0000] {subprocess.py:93} INFO -   23. DB::TCPHandler::run() @ 0x0000000019e4f119
[2025-10-31T22:13:48.370+0000] {subprocess.py:93} INFO -   24. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
[2025-10-31T22:13:48.371+0000] {subprocess.py:93} INFO -   25. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
[2025-10-31T22:13:48.372+0000] {subprocess.py:93} INFO -   26. Poco::PooledThread::run() @ 0x000000001ef15b87
[2025-10-31T22:13:48.372+0000] {subprocess.py:93} INFO -   27. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
[2025-10-31T22:13:48.373+0000] {subprocess.py:93} INFO -   28. ? @ 0x0000000000094ac3
[2025-10-31T22:13:48.374+0000] {subprocess.py:93} INFO -   29. ? @ 0x0000000000125a74
[2025-10-31T22:13:48.374+0000] {subprocess.py:93} INFO - 22:13:48
[2025-10-31T22:13:48.374+0000] {subprocess.py:93} INFO - 22:13:48    compiled code at target/compiled/ck_project/models/silver/silver_payments.sql
[2025-10-31T22:13:48.375+0000] {subprocess.py:93} INFO - 22:13:48
[2025-10-31T22:13:48.375+0000] {subprocess.py:93} INFO - 22:13:48  Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T22:13:49.327+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-10-31T22:13:49.343+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-10-31T22:13:49.347+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T221340, end_date=20251031T221349
[2025-10-31T22:13:49.365+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 12 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 1.; 310)
[2025-10-31T22:13:49.395+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-10-31T22:13:49.421+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T22:47:08.536+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:47:08.559+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:47:08.566+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-10-31T22:47:08.590+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T22:47:08.602+0000] {standard_task_runner.py:60} INFO - Started process 424 to run task
[2025-10-31T22:47:08.608+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpl29v3atg']
[2025-10-31T22:47:08.612+0000] {standard_task_runner.py:88} INFO - Job 15: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T22:47:08.739+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host d335ca5d7801
[2025-10-31T22:47:08.883+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T22:47:08.886+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T22:47:08.890+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 0\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T22:47:08.911+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T22:47:09.117+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-30"}
[2025-10-31T22:47:11.344+0000] {subprocess.py:93} INFO - 22:47:11  Running with dbt=1.10.13
[2025-10-31T22:47:11.614+0000] {subprocess.py:93} INFO - 22:47:11  Registered adapter: clickhouse=1.9.5
[2025-10-31T22:47:11.801+0000] {subprocess.py:93} INFO - 22:47:11  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T22:47:13.477+0000] {subprocess.py:93} INFO - 22:47:13  Found 3 models, 3 sources, 488 macros
[2025-10-31T22:47:13.483+0000] {subprocess.py:93} INFO - 22:47:13
[2025-10-31T22:47:13.485+0000] {subprocess.py:93} INFO - 22:47:13  Concurrency: 4 threads (target='dev')
[2025-10-31T22:47:13.487+0000] {subprocess.py:93} INFO - 22:47:13
[2025-10-31T22:47:13.901+0000] {subprocess.py:93} INFO - 22:47:13  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T22:47:13.902+0000] {subprocess.py:93} INFO - 22:47:13  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T22:47:14.188+0000] {subprocess.py:93} INFO - 22:47:14  1 of 2 ERROR creating sql incremental model `silver`.`silver_link_transactions`  [ERROR in 0.28s]
[2025-10-31T22:47:14.352+0000] {subprocess.py:93} INFO - 22:47:14  2 of 2 OK created sql incremental model `silver`.`silver_payments` ............. [OK in 0.44s]
[2025-10-31T22:47:14.369+0000] {subprocess.py:93} INFO - 22:47:14
[2025-10-31T22:47:14.371+0000] {subprocess.py:93} INFO - 22:47:14  Finished running 2 incremental models in 0 hours 0 minutes and 0.88 seconds (0.88s).
[2025-10-31T22:47:14.596+0000] {subprocess.py:93} INFO - 22:47:14
[2025-10-31T22:47:14.598+0000] {subprocess.py:93} INFO - 22:47:14  Completed with 1 error, 0 partial successes, and 0 warnings:
[2025-10-31T22:47:14.600+0000] {subprocess.py:93} INFO - 22:47:14
[2025-10-31T22:47:14.601+0000] {subprocess.py:93} INFO - 22:47:14  Failure in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-10-31T22:47:14.604+0000] {subprocess.py:93} INFO - 22:47:14    Database Error in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-10-31T22:47:14.605+0000] {subprocess.py:93} INFO -   Code: 57.
[2025-10-31T22:47:14.605+0000] {subprocess.py:93} INFO -   DB::Exception: Table silver.silver_link_transactions already exists. Stack trace:
[2025-10-31T22:47:14.606+0000] {subprocess.py:93} INFO - 
[2025-10-31T22:47:14.607+0000] {subprocess.py:93} INFO -   0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
[2025-10-31T22:47:14.608+0000] {subprocess.py:93} INFO -   1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
[2025-10-31T22:47:14.609+0000] {subprocess.py:93} INFO -   2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
[2025-10-31T22:47:14.609+0000] {subprocess.py:93} INFO -   3. DB::Exception::Exception<String, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String>::type>, String&&, String&&) @ 0x000000000cae72ab
[2025-10-31T22:47:14.610+0000] {subprocess.py:93} INFO -   4. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000182fd9db
[2025-10-31T22:47:14.612+0000] {subprocess.py:93} INFO -   5. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ef810
[2025-10-31T22:47:14.613+0000] {subprocess.py:93} INFO -   6. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
[2025-10-31T22:47:14.614+0000] {subprocess.py:93} INFO -   7. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
[2025-10-31T22:47:14.615+0000] {subprocess.py:93} INFO -   8. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
[2025-10-31T22:47:14.617+0000] {subprocess.py:93} INFO -   9. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
[2025-10-31T22:47:14.619+0000] {subprocess.py:93} INFO -   10. DB::TCPHandler::run() @ 0x0000000019e4f119
[2025-10-31T22:47:14.620+0000] {subprocess.py:93} INFO -   11. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
[2025-10-31T22:47:14.620+0000] {subprocess.py:93} INFO -   12. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
[2025-10-31T22:47:14.622+0000] {subprocess.py:93} INFO -   13. Poco::PooledThread::run() @ 0x000000001ef15b87
[2025-10-31T22:47:14.623+0000] {subprocess.py:93} INFO -   14. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
[2025-10-31T22:47:14.624+0000] {subprocess.py:93} INFO -   15. ? @ 0x0000000000094ac3
[2025-10-31T22:47:14.624+0000] {subprocess.py:93} INFO -   16. ? @ 0x0000000000125a74
[2025-10-31T22:47:14.625+0000] {subprocess.py:93} INFO - 22:47:14
[2025-10-31T22:47:14.626+0000] {subprocess.py:93} INFO - 22:47:14    compiled code at target/compiled/ck_project/models/silver/silver_link_transactions.sql
[2025-10-31T22:47:14.629+0000] {subprocess.py:93} INFO - 22:47:14
[2025-10-31T22:47:14.630+0000] {subprocess.py:93} INFO - 22:47:14  Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T22:47:15.752+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-10-31T22:47:15.768+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-10-31T22:47:15.773+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T224708, end_date=20251031T224715
[2025-10-31T22:47:15.790+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 15 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 1.; 424)
[2025-10-31T22:47:15.839+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-10-31T22:47:15.868+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T22:58:44.883+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:58:44.897+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:58:44.897+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-10-31T22:58:44.923+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T22:58:44.932+0000] {standard_task_runner.py:60} INFO - Started process 386 to run task
[2025-10-31T22:58:44.939+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmp9kwxw_pc']
[2025-10-31T22:58:44.942+0000] {standard_task_runner.py:88} INFO - Job 14: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T22:58:45.046+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host ad620feb6bee
[2025-10-31T22:58:45.178+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T22:58:45.180+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T22:58:45.181+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 0\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T22:58:45.195+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T22:58:45.359+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-30"}
[2025-10-31T22:58:47.928+0000] {subprocess.py:93} INFO - 22:58:47  Running with dbt=1.10.13
[2025-10-31T22:58:48.334+0000] {subprocess.py:93} INFO - 22:58:48  Registered adapter: clickhouse=1.9.5
[2025-10-31T22:58:49.343+0000] {subprocess.py:93} INFO - 22:58:49  Found 3 models, 3 sources, 491 macros
[2025-10-31T22:58:49.348+0000] {subprocess.py:93} INFO - 22:58:49
[2025-10-31T22:58:49.349+0000] {subprocess.py:93} INFO - 22:58:49  Concurrency: 4 threads (target='dev')
[2025-10-31T22:58:49.351+0000] {subprocess.py:93} INFO - 22:58:49
[2025-10-31T22:58:49.804+0000] {subprocess.py:93} INFO - 22:58:49  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T22:58:49.806+0000] {subprocess.py:93} INFO - 22:58:49  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T22:58:50.029+0000] {subprocess.py:93} INFO - 22:58:50  1 of 2 ERROR creating sql incremental model `silver`.`silver_link_transactions`  [ERROR in 0.22s]
[2025-10-31T22:58:50.030+0000] {subprocess.py:93} INFO - 22:58:50  2 of 2 ERROR creating sql incremental model `silver`.`silver_payments` ......... [ERROR in 0.22s]
[2025-10-31T22:58:50.045+0000] {subprocess.py:93} INFO - 22:58:50
[2025-10-31T22:58:50.046+0000] {subprocess.py:93} INFO - 22:58:50  Finished running 2 incremental models in 0 hours 0 minutes and 0.69 seconds (0.69s).
[2025-10-31T22:58:50.111+0000] {subprocess.py:93} INFO - 22:58:50
[2025-10-31T22:58:50.113+0000] {subprocess.py:93} INFO - 22:58:50  Completed with 2 errors, 0 partial successes, and 0 warnings:
[2025-10-31T22:58:50.115+0000] {subprocess.py:93} INFO - 22:58:50
[2025-10-31T22:58:50.117+0000] {subprocess.py:93} INFO - 22:58:50  Failure in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-10-31T22:58:50.118+0000] {subprocess.py:93} INFO - 22:58:50    Compilation Error in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-10-31T22:58:50.119+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-10-31T22:58:50.120+0000] {subprocess.py:93} INFO - 
[2025-10-31T22:58:50.120+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-10-31T22:58:50.121+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-10-31T22:58:50.122+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-10-31T22:58:50.122+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-10-31T22:58:50.123+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-10-31T22:58:50.124+0000] {subprocess.py:93} INFO -   > called by model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-10-31T22:58:50.125+0000] {subprocess.py:93} INFO - 22:58:50
[2025-10-31T22:58:50.126+0000] {subprocess.py:93} INFO - 22:58:50    compiled code at target/compiled/ck_project/models/silver/silver_link_transactions.sql
[2025-10-31T22:58:50.127+0000] {subprocess.py:93} INFO - 22:58:50
[2025-10-31T22:58:50.128+0000] {subprocess.py:93} INFO - 22:58:50  Failure in model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T22:58:50.128+0000] {subprocess.py:93} INFO - 22:58:50    Compilation Error in model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T22:58:50.129+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-10-31T22:58:50.129+0000] {subprocess.py:93} INFO - 
[2025-10-31T22:58:50.130+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-10-31T22:58:50.130+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-10-31T22:58:50.131+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-10-31T22:58:50.131+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-10-31T22:58:50.132+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-10-31T22:58:50.132+0000] {subprocess.py:93} INFO -   > called by model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T22:58:50.133+0000] {subprocess.py:93} INFO - 22:58:50
[2025-10-31T22:58:50.134+0000] {subprocess.py:93} INFO - 22:58:50    compiled code at target/compiled/ck_project/models/silver/silver_payments.sql
[2025-10-31T22:58:50.134+0000] {subprocess.py:93} INFO - 22:58:50
[2025-10-31T22:58:50.135+0000] {subprocess.py:93} INFO - 22:58:50  Done. PASS=0 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T22:58:51.187+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-10-31T22:58:51.205+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-10-31T22:58:51.212+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T225844, end_date=20251031T225851
[2025-10-31T22:58:51.234+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 14 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 1.; 386)
[2025-10-31T22:58:51.270+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-10-31T22:58:51.292+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-11-01T11:40:54.196+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-11-01T11:40:54.236+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-11-01T11:40:54.247+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-11-01T11:40:54.288+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-11-01T11:40:54.304+0000] {standard_task_runner.py:60} INFO - Started process 532 to run task
[2025-11-01T11:40:54.314+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpfkv5kc62']
[2025-11-01T11:40:54.325+0000] {standard_task_runner.py:88} INFO - Job 19: Subtask silver_dbt.dbt_run_incrementals
[2025-11-01T11:40:54.587+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host 6ac9b46937d1
[2025-11-01T11:40:54.916+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-11-01T11:40:54.919+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-11-01T11:40:54.923+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 0\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-11-01T11:40:54.956+0000] {subprocess.py:86} INFO - Output:
[2025-11-01T11:40:55.280+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-30"}
[2025-11-01T11:41:00.296+0000] {subprocess.py:93} INFO - 11:41:00  Running with dbt=1.10.13
[2025-11-01T11:41:01.112+0000] {subprocess.py:93} INFO - 11:41:01  Registered adapter: clickhouse=1.9.5
[2025-11-01T11:41:01.688+0000] {subprocess.py:93} INFO - 11:41:01  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-11-01T11:41:05.976+0000] {subprocess.py:93} INFO - 11:41:05  Found 3 models, 3 sources, 491 macros
[2025-11-01T11:41:05.980+0000] {subprocess.py:93} INFO - 11:41:05
[2025-11-01T11:41:06.001+0000] {subprocess.py:93} INFO - 11:41:05  Concurrency: 4 threads (target='dev')
[2025-11-01T11:41:06.009+0000] {subprocess.py:93} INFO - 11:41:05
[2025-11-01T11:41:06.846+0000] {subprocess.py:93} INFO - 11:41:06  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-11-01T11:41:06.849+0000] {subprocess.py:93} INFO - 11:41:06  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-11-01T11:41:07.191+0000] {subprocess.py:93} INFO - 11:41:07  2 of 2 ERROR creating sql incremental model `silver`.`silver_payments` ......... [ERROR in 0.30s]
[2025-11-01T11:41:07.193+0000] {subprocess.py:93} INFO - 11:41:07  1 of 2 ERROR creating sql incremental model `silver`.`silver_link_transactions`  [ERROR in 0.31s]
[2025-11-01T11:41:07.267+0000] {subprocess.py:93} INFO - 11:41:07
[2025-11-01T11:41:07.270+0000] {subprocess.py:93} INFO - 11:41:07  Finished running 2 incremental models in 0 hours 0 minutes and 1.27 seconds (1.27s).
[2025-11-01T11:41:07.586+0000] {subprocess.py:93} INFO - 11:41:07
[2025-11-01T11:41:07.590+0000] {subprocess.py:93} INFO - 11:41:07  Completed with 2 errors, 0 partial successes, and 0 warnings:
[2025-11-01T11:41:07.594+0000] {subprocess.py:93} INFO - 11:41:07
[2025-11-01T11:41:07.597+0000] {subprocess.py:93} INFO - 11:41:07  Failure in model silver_payments (models/silver/silver_payments.sql)
[2025-11-01T11:41:07.604+0000] {subprocess.py:93} INFO - 11:41:07    Compilation Error in model silver_payments (models/silver/silver_payments.sql)
[2025-11-01T11:41:07.605+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-11-01T11:41:07.608+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:41:07.609+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-11-01T11:41:07.610+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:41:07.611+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:41:07.612+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-11-01T11:41:07.613+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-11-01T11:41:07.614+0000] {subprocess.py:93} INFO -   > called by model silver_payments (models/silver/silver_payments.sql)
[2025-11-01T11:41:07.615+0000] {subprocess.py:93} INFO - 11:41:07
[2025-11-01T11:41:07.621+0000] {subprocess.py:93} INFO - 11:41:07    compiled code at target/compiled/ck_project/models/silver/silver_payments.sql
[2025-11-01T11:41:07.628+0000] {subprocess.py:93} INFO - 11:41:07
[2025-11-01T11:41:07.630+0000] {subprocess.py:93} INFO - 11:41:07  Failure in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-11-01T11:41:07.636+0000] {subprocess.py:93} INFO - 11:41:07    Compilation Error in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-11-01T11:41:07.637+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-11-01T11:41:07.638+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:41:07.639+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-11-01T11:41:07.640+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:41:07.640+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:41:07.641+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-11-01T11:41:07.642+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-11-01T11:41:07.643+0000] {subprocess.py:93} INFO -   > called by model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-11-01T11:41:07.650+0000] {subprocess.py:93} INFO - 11:41:07
[2025-11-01T11:41:07.651+0000] {subprocess.py:93} INFO - 11:41:07    compiled code at target/compiled/ck_project/models/silver/silver_link_transactions.sql
[2025-11-01T11:41:07.652+0000] {subprocess.py:93} INFO - 11:41:07
[2025-11-01T11:41:07.653+0000] {subprocess.py:93} INFO - 11:41:07  Done. PASS=0 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=2
[2025-11-01T11:41:09.032+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-11-01T11:41:09.060+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-11-01T11:41:09.066+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251101T114054, end_date=20251101T114109
[2025-11-01T11:41:09.094+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 19 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 1.; 532)
[2025-11-01T11:41:09.124+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-11-01T11:41:09.150+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
