[2025-10-31T19:11:53.656+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T19:11:53.665+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T19:11:53.665+0000] {taskinstance.py:2170} INFO - Starting attempt 2 of 2
[2025-10-31T19:11:53.680+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T19:11:53.685+0000] {standard_task_runner.py:60} INFO - Started process 1226 to run task
[2025-10-31T19:11:53.691+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '41', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpmb1iozis']
[2025-10-31T19:11:53.694+0000] {standard_task_runner.py:88} INFO - Job 41: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T19:11:53.785+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host fe1087a1e328
[2025-10-31T19:11:53.880+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T19:11:53.882+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T19:11:53.883+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'set -e; cd /dbt; python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 29\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n| tee /tmp/dbt_vars.json > /dev/null; echo "dbt vars => $(cat /tmp/dbt_vars.json)"; dbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "$(cat /tmp/dbt_vars.json)"\'']
[2025-10-31T19:11:53.892+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T19:11:54.044+0000] {subprocess.py:93} INFO - {"ds_lagged": "2025-10-01"}
[2025-10-31T19:11:54.047+0000] {subprocess.py:93} INFO - bash: -c: line 9: syntax error near unexpected token `|'
[2025-10-31T19:11:54.054+0000] {subprocess.py:97} INFO - Command exited with return code 2
[2025-10-31T19:11:54.066+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2025-10-31T19:11:54.070+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T191153, end_date=20251031T191154
[2025-10-31T19:11:54.083+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 41 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 2.; 1226)
[2025-10-31T19:11:54.104+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-10-31T19:11:54.123+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T22:05:31.791+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:05:31.805+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:05:31.805+0000] {taskinstance.py:2170} INFO - Starting attempt 2 of 2
[2025-10-31T22:05:31.825+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T22:05:31.832+0000] {standard_task_runner.py:60} INFO - Started process 774 to run task
[2025-10-31T22:05:31.837+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '20', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmp9xt2rs0v']
[2025-10-31T22:05:31.844+0000] {standard_task_runner.py:88} INFO - Job 20: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T22:05:31.953+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host 9dbfb6fb81d8
[2025-10-31T22:05:32.099+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T22:05:32.102+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T22:05:32.104+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 0\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T22:05:32.119+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T22:05:32.286+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-30"}
[2025-10-31T22:05:34.214+0000] {subprocess.py:93} INFO - 22:05:34  Running with dbt=1.10.13
[2025-10-31T22:05:34.458+0000] {subprocess.py:93} INFO - 22:05:34  Registered adapter: clickhouse=1.9.5
[2025-10-31T22:05:34.609+0000] {subprocess.py:93} INFO - 22:05:34  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T22:05:36.043+0000] {subprocess.py:93} INFO - 22:05:36  Found 3 models, 3 sources, 488 macros
[2025-10-31T22:05:36.047+0000] {subprocess.py:93} INFO - 22:05:36
[2025-10-31T22:05:36.049+0000] {subprocess.py:93} INFO - 22:05:36  Concurrency: 4 threads (target='dev')
[2025-10-31T22:05:36.051+0000] {subprocess.py:93} INFO - 22:05:36
[2025-10-31T22:05:36.291+0000] {subprocess.py:93} INFO - 22:05:36  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T22:05:36.292+0000] {subprocess.py:93} INFO - 22:05:36  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T22:05:36.549+0000] {subprocess.py:93} INFO - 22:05:36  2 of 2 ERROR creating sql incremental model `silver`.`silver_payments` ......... [ERROR in 0.25s]
[2025-10-31T22:05:36.655+0000] {subprocess.py:93} INFO - 22:05:36  1 of 2 OK created sql incremental model `silver`.`silver_link_transactions` .... [OK in 0.36s]
[2025-10-31T22:05:36.665+0000] {subprocess.py:93} INFO - 22:05:36
[2025-10-31T22:05:36.666+0000] {subprocess.py:93} INFO - 22:05:36  Finished running 2 incremental models in 0 hours 0 minutes and 0.61 seconds (0.61s).
[2025-10-31T22:05:36.800+0000] {subprocess.py:93} INFO - 22:05:36
[2025-10-31T22:05:36.802+0000] {subprocess.py:93} INFO - 22:05:36  Completed with 1 error, 0 partial successes, and 0 warnings:
[2025-10-31T22:05:36.803+0000] {subprocess.py:93} INFO - 22:05:36
[2025-10-31T22:05:36.805+0000] {subprocess.py:93} INFO - 22:05:36  Failure in model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T22:05:36.806+0000] {subprocess.py:93} INFO - 22:05:36    Database Error in model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T22:05:36.807+0000] {subprocess.py:93} INFO -   Code: 60.
[2025-10-31T22:05:36.808+0000] {subprocess.py:93} INFO -   DB::Exception: Unknown table expression identifier 'bronze.payments' in scope  raw. Stack trace:
[2025-10-31T22:05:36.809+0000] {subprocess.py:93} INFO - 
[2025-10-31T22:05:36.809+0000] {subprocess.py:93} INFO -   0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x00000000137a855f
[2025-10-31T22:05:36.810+0000] {subprocess.py:93} INFO -   1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cae7e8e
[2025-10-31T22:05:36.811+0000] {subprocess.py:93} INFO -   2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cae7940
[2025-10-31T22:05:36.812+0000] {subprocess.py:93} INFO -   3. DB::Exception::Exception<String const&, String>(int, FormatStringHelperImpl<std::type_identity<String const&>::type, std::type_identity<String>::type>, String const&, String&&) @ 0x000000000db773ab
[2025-10-31T22:05:36.812+0000] {subprocess.py:93} INFO -   4. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x0000000017830745
[2025-10-31T22:05:36.813+0000] {subprocess.py:93} INFO -   5. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x0000000017837221
[2025-10-31T22:05:36.813+0000] {subprocess.py:93} INFO -   6. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785ae58
[2025-10-31T22:05:36.814+0000] {subprocess.py:93} INFO -   7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
[2025-10-31T22:05:36.814+0000] {subprocess.py:93} INFO -   8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x0000000017837221
[2025-10-31T22:05:36.815+0000] {subprocess.py:93} INFO -   9. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001785ae58
[2025-10-31T22:05:36.815+0000] {subprocess.py:93} INFO -   10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x000000001782d021
[2025-10-31T22:05:36.816+0000] {subprocess.py:93} INFO -   11. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001782a87a
[2025-10-31T22:05:36.817+0000] {subprocess.py:93} INFO -   12. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000017829edc
[2025-10-31T22:05:36.817+0000] {subprocess.py:93} INFO -   13. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x000000001787d276
[2025-10-31T22:05:36.817+0000] {subprocess.py:93} INFO -   14. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.8096503222789336007) @ 0x00000000183bd40d
[2025-10-31T22:05:36.818+0000] {subprocess.py:93} INFO -   15. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x00000000183bb32a
[2025-10-31T22:05:36.818+0000] {subprocess.py:93} INFO -   16. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x00000000183bd86a
[2025-10-31T22:05:36.819+0000] {subprocess.py:93} INFO -   17. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000182e49d3
[2025-10-31T22:05:36.819+0000] {subprocess.py:93} INFO -   18. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000182ed2c5
[2025-10-31T22:05:36.820+0000] {subprocess.py:93} INFO -   19. DB::InterpreterCreateQuery::execute() @ 0x0000000018303978
[2025-10-31T22:05:36.820+0000] {subprocess.py:93} INFO -   20. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>) @ 0x0000000018780440
[2025-10-31T22:05:36.821+0000] {subprocess.py:93} INFO -   21. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x00000000187786cb
[2025-10-31T22:05:36.821+0000] {subprocess.py:93} INFO -   22. DB::TCPHandler::runImpl() @ 0x0000000019e2d3db
[2025-10-31T22:05:36.822+0000] {subprocess.py:93} INFO -   23. DB::TCPHandler::run() @ 0x0000000019e4f119
[2025-10-31T22:05:36.824+0000] {subprocess.py:93} INFO -   24. Poco::Net::TCPServerConnection::start() @ 0x000000001ef4ed07
[2025-10-31T22:05:36.825+0000] {subprocess.py:93} INFO -   25. Poco::Net::TCPServerDispatcher::run() @ 0x000000001ef4f199
[2025-10-31T22:05:36.826+0000] {subprocess.py:93} INFO -   26. Poco::PooledThread::run() @ 0x000000001ef15b87
[2025-10-31T22:05:36.827+0000] {subprocess.py:93} INFO -   27. Poco::ThreadImpl::runnableEntry(void*) @ 0x000000001ef13f81
[2025-10-31T22:05:36.827+0000] {subprocess.py:93} INFO -   28. ? @ 0x0000000000094ac3
[2025-10-31T22:05:36.828+0000] {subprocess.py:93} INFO -   29. ? @ 0x0000000000125a74
[2025-10-31T22:05:36.829+0000] {subprocess.py:93} INFO - 22:05:36
[2025-10-31T22:05:36.829+0000] {subprocess.py:93} INFO - 22:05:36    compiled code at target/compiled/ck_project/models/silver/silver_payments.sql
[2025-10-31T22:05:36.830+0000] {subprocess.py:93} INFO - 22:05:36
[2025-10-31T22:05:36.830+0000] {subprocess.py:93} INFO - 22:05:36  Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T22:05:37.637+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-10-31T22:05:37.650+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-10-31T22:05:37.652+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T220531, end_date=20251031T220537
[2025-10-31T22:05:37.675+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 20 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 1.; 774)
[2025-10-31T22:05:37.688+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-10-31T22:05:37.710+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T22:52:16.259+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:52:16.313+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T22:52:16.320+0000] {taskinstance.py:2170} INFO - Starting attempt 2 of 2
[2025-10-31T22:52:16.343+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T22:52:16.349+0000] {standard_task_runner.py:60} INFO - Started process 808 to run task
[2025-10-31T22:52:16.353+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpw9qjm3rr']
[2025-10-31T22:52:16.356+0000] {standard_task_runner.py:88} INFO - Job 19: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T22:52:16.439+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host d335ca5d7801
[2025-10-31T22:52:16.535+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T22:52:16.538+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T22:52:16.540+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 0\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T22:52:16.556+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T22:52:16.683+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-30"}
[2025-10-31T22:52:18.472+0000] {subprocess.py:93} INFO - 22:52:18  Running with dbt=1.10.13
[2025-10-31T22:52:18.719+0000] {subprocess.py:93} INFO - 22:52:18  Registered adapter: clickhouse=1.9.5
[2025-10-31T22:52:18.879+0000] {subprocess.py:93} INFO - 22:52:18  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T22:52:20.292+0000] {subprocess.py:93} INFO - 22:52:20  Found 3 models, 3 sources, 488 macros
[2025-10-31T22:52:20.297+0000] {subprocess.py:93} INFO - 22:52:20
[2025-10-31T22:52:20.298+0000] {subprocess.py:93} INFO - 22:52:20  Concurrency: 4 threads (target='dev')
[2025-10-31T22:52:20.300+0000] {subprocess.py:93} INFO - 22:52:20
[2025-10-31T22:52:20.522+0000] {subprocess.py:93} INFO - 22:52:20  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T22:52:20.523+0000] {subprocess.py:93} INFO - 22:52:20  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T22:52:20.961+0000] {subprocess.py:93} INFO - 22:52:20  1 of 2 OK created sql incremental model `silver`.`silver_link_transactions` .... [OK in 0.43s]
[2025-10-31T22:52:20.987+0000] {subprocess.py:93} INFO - 22:52:20  2 of 2 OK created sql incremental model `silver`.`silver_payments` ............. [OK in 0.46s]
[2025-10-31T22:52:20.997+0000] {subprocess.py:93} INFO - 22:52:20
[2025-10-31T22:52:20.998+0000] {subprocess.py:93} INFO - 22:52:20  Finished running 2 incremental models in 0 hours 0 minutes and 0.70 seconds (0.70s).
[2025-10-31T22:52:21.059+0000] {subprocess.py:93} INFO - 22:52:21
[2025-10-31T22:52:21.061+0000] {subprocess.py:93} INFO - 22:52:21  Completed successfully
[2025-10-31T22:52:21.062+0000] {subprocess.py:93} INFO - 22:52:21
[2025-10-31T22:52:21.064+0000] {subprocess.py:93} INFO - 22:52:21  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T22:52:21.881+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-10-31T22:52:21.917+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T225216, end_date=20251031T225221
[2025-10-31T22:52:21.955+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-10-31T22:52:21.972+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T23:03:52.101+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T23:03:52.111+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-10-31T23:03:52.111+0000] {taskinstance.py:2170} INFO - Starting attempt 2 of 2
[2025-10-31T23:03:52.127+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-10-31T23:03:52.132+0000] {standard_task_runner.py:60} INFO - Started process 767 to run task
[2025-10-31T23:03:52.136+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmpzz6jk6p6']
[2025-10-31T23:03:52.138+0000] {standard_task_runner.py:88} INFO - Job 16: Subtask silver_dbt.dbt_run_incrementals
[2025-10-31T23:03:52.231+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host ad620feb6bee
[2025-10-31T23:03:52.370+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-10-31T23:03:52.374+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T23:03:52.377+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -e\ncd /dbt\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 0\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\'']
[2025-10-31T23:03:52.395+0000] {subprocess.py:86} INFO - Output:
[2025-10-31T23:03:52.540+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-30"}
[2025-10-31T23:03:54.808+0000] {subprocess.py:93} INFO - 23:03:54  Running with dbt=1.10.13
[2025-10-31T23:03:55.216+0000] {subprocess.py:93} INFO - 23:03:55  Registered adapter: clickhouse=1.9.5
[2025-10-31T23:03:55.438+0000] {subprocess.py:93} INFO - 23:03:55  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-10-31T23:03:57.337+0000] {subprocess.py:93} INFO - 23:03:57  Found 3 models, 3 sources, 491 macros
[2025-10-31T23:03:57.342+0000] {subprocess.py:93} INFO - 23:03:57
[2025-10-31T23:03:57.346+0000] {subprocess.py:93} INFO - 23:03:57  Concurrency: 4 threads (target='dev')
[2025-10-31T23:03:57.349+0000] {subprocess.py:93} INFO - 23:03:57
[2025-10-31T23:03:57.745+0000] {subprocess.py:93} INFO - 23:03:57  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-10-31T23:03:57.746+0000] {subprocess.py:93} INFO - 23:03:57  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-10-31T23:03:58.038+0000] {subprocess.py:93} INFO - 23:03:58  1 of 2 ERROR creating sql incremental model `silver`.`silver_link_transactions`  [ERROR in 0.28s]
[2025-10-31T23:03:58.042+0000] {subprocess.py:93} INFO - 23:03:58  2 of 2 ERROR creating sql incremental model `silver`.`silver_payments` ......... [ERROR in 0.27s]
[2025-10-31T23:03:58.068+0000] {subprocess.py:93} INFO - 23:03:58
[2025-10-31T23:03:58.071+0000] {subprocess.py:93} INFO - 23:03:58  Finished running 2 incremental models in 0 hours 0 minutes and 0.72 seconds (0.72s).
[2025-10-31T23:03:58.140+0000] {subprocess.py:93} INFO - 23:03:58
[2025-10-31T23:03:58.141+0000] {subprocess.py:93} INFO - 23:03:58  Completed with 2 errors, 0 partial successes, and 0 warnings:
[2025-10-31T23:03:58.144+0000] {subprocess.py:93} INFO - 23:03:58
[2025-10-31T23:03:58.145+0000] {subprocess.py:93} INFO - 23:03:58  Failure in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-10-31T23:03:58.146+0000] {subprocess.py:93} INFO - 23:03:58    Compilation Error in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-10-31T23:03:58.147+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-10-31T23:03:58.148+0000] {subprocess.py:93} INFO - 
[2025-10-31T23:03:58.148+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-10-31T23:03:58.149+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-10-31T23:03:58.149+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-10-31T23:03:58.150+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-10-31T23:03:58.150+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-10-31T23:03:58.150+0000] {subprocess.py:93} INFO -   > called by model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-10-31T23:03:58.151+0000] {subprocess.py:93} INFO - 23:03:58
[2025-10-31T23:03:58.152+0000] {subprocess.py:93} INFO - 23:03:58    compiled code at target/compiled/ck_project/models/silver/silver_link_transactions.sql
[2025-10-31T23:03:58.152+0000] {subprocess.py:93} INFO - 23:03:58
[2025-10-31T23:03:58.153+0000] {subprocess.py:93} INFO - 23:03:58  Failure in model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T23:03:58.154+0000] {subprocess.py:93} INFO - 23:03:58    Compilation Error in model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T23:03:58.154+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-10-31T23:03:58.154+0000] {subprocess.py:93} INFO - 
[2025-10-31T23:03:58.155+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-10-31T23:03:58.155+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-10-31T23:03:58.156+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-10-31T23:03:58.156+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-10-31T23:03:58.157+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-10-31T23:03:58.157+0000] {subprocess.py:93} INFO -   > called by model silver_payments (models/silver/silver_payments.sql)
[2025-10-31T23:03:58.158+0000] {subprocess.py:93} INFO - 23:03:58
[2025-10-31T23:03:58.158+0000] {subprocess.py:93} INFO - 23:03:58    compiled code at target/compiled/ck_project/models/silver/silver_payments.sql
[2025-10-31T23:03:58.159+0000] {subprocess.py:93} INFO - 23:03:58
[2025-10-31T23:03:58.159+0000] {subprocess.py:93} INFO - 23:03:58  Done. PASS=0 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=2
[2025-10-31T23:03:59.340+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-10-31T23:03:59.359+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-10-31T23:03:59.363+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251031T230352, end_date=20251031T230359
[2025-10-31T23:03:59.381+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 16 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 1.; 767)
[2025-10-31T23:03:59.407+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-10-31T23:03:59.426+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-11-01T11:46:09.671+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-11-01T11:46:09.690+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [queued]>
[2025-11-01T11:46:09.691+0000] {taskinstance.py:2170} INFO - Starting attempt 2 of 2
[2025-11-01T11:46:09.726+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): silver_dbt.dbt_run_incrementals> on 2025-10-30 00:00:00+00:00
[2025-11-01T11:46:09.740+0000] {standard_task_runner.py:60} INFO - Started process 1128 to run task
[2025-11-01T11:46:09.752+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ingestion_pipeline', 'silver_dbt.dbt_run_incrementals', 'scheduled__2025-10-30T00:00:00+00:00', '--job-id', '47', '--raw', '--subdir', 'DAGS_FOLDER/ingestion_dag.py', '--cfg-path', '/tmp/tmp_s9wl3ru']
[2025-11-01T11:46:09.756+0000] {standard_task_runner.py:88} INFO - Job 47: Subtask silver_dbt.dbt_run_incrementals
[2025-11-01T11:46:09.924+0000] {task_command.py:423} INFO - Running <TaskInstance: ingestion_pipeline.silver_dbt.dbt_run_incrementals scheduled__2025-10-30T00:00:00+00:00 [running]> on host 6ac9b46937d1
[2025-11-01T11:46:10.140+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='ingestion_pipeline' AIRFLOW_CTX_TASK_ID='silver_dbt.dbt_run_incrementals' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T00:00:00+00:00'
[2025-11-01T11:46:10.143+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-11-01T11:46:10.145+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'docker exec -i dbt bash -lc \'\nset -euo pipefail\ncd /dbt\n\n# Build vars JSON for the lagged day\nDBT_VARS=$(python - <<"PY"\nfrom datetime import datetime, timedelta\nimport json\nds = "2025-10-30"\nlag_days = 0\nlagged = (datetime.strptime(ds, "%Y-%m-%d") - timedelta(days=lag_days)).strftime("%Y-%m-%d")\nprint(json.dumps({"ds_lagged": lagged}))\nPY\n)\necho "dbt vars => ${DBT_VARS}"\n\n# 1) Always compile so we have files to inspect on failure\ndbt --no-use-colors compile --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}"\n\n# 2) Run; if it fails, print compiled SQL + last 200 log lines\nset +e\ndbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars "${DBT_VARS}" --debug\nstatus=$?\nif [ $status -ne 0 ]; then\n  echo \'---- COMPILED SQL: silver_payments ----\'\n  cat target/compiled/*/models/silver/silver_payments.sql 2>/dev/null || true\n  echo \'---- COMPILED SQL: silver_link_transactions ----\'\n  cat target/compiled/*/models/silver/silver_link_transactions.sql 2>/dev/null || true\n  echo \'---- LAST 200 LINES OF logs/dbt.log ----\'\n  tail -n 200 logs/dbt.log 2>/dev/null || true\n  exit $status\nfi\n\'']
[2025-11-01T11:46:10.166+0000] {subprocess.py:86} INFO - Output:
[2025-11-01T11:46:10.384+0000] {subprocess.py:93} INFO - dbt vars => {"ds_lagged": "2025-10-30"}
[2025-11-01T11:46:12.961+0000] {subprocess.py:93} INFO - 11:46:12  Running with dbt=1.10.13
[2025-11-01T11:46:13.412+0000] {subprocess.py:93} INFO - 11:46:13  Registered adapter: clickhouse=1.9.5
[2025-11-01T11:46:13.687+0000] {subprocess.py:93} INFO - 11:46:13  Unable to do partial parsing because config vars, config profile, or config target have changed
[2025-11-01T11:46:16.120+0000] {subprocess.py:93} INFO - 11:46:16  Found 3 models, 3 sources, 491 macros
[2025-11-01T11:46:16.131+0000] {subprocess.py:93} INFO - 11:46:16
[2025-11-01T11:46:16.136+0000] {subprocess.py:93} INFO - 11:46:16  Concurrency: 4 threads (target='dev')
[2025-11-01T11:46:16.141+0000] {subprocess.py:93} INFO - 11:46:16
[2025-11-01T11:46:16.691+0000] {subprocess.py:93} INFO - Compiled node 'silver_payments' is:
[2025-11-01T11:46:16.692+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.692+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.694+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.696+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.697+0000] {subprocess.py:93} INFO - with raw as (
[2025-11-01T11:46:16.698+0000] {subprocess.py:93} INFO -     select
[2025-11-01T11:46:16.698+0000] {subprocess.py:93} INFO -         -- Cast IDs defensively
[2025-11-01T11:46:16.699+0000] {subprocess.py:93} INFO -         toUInt64OrNull(id)           as payment_id,
[2025-11-01T11:46:16.700+0000] {subprocess.py:93} INFO -         toUInt64OrNull(merchant_id)  as merchant_id,
[2025-11-01T11:46:16.701+0000] {subprocess.py:93} INFO -         toUInt64OrNull(acquirer_id)  as acquirer_id,
[2025-11-01T11:46:16.702+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.702+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.703+0000] {subprocess.py:93} INFO -         -- Strings only; avoid optional JSON columns for now
[2025-11-01T11:46:16.704+0000] {subprocess.py:93} INFO -         toLowCardinality(state)      as state,
[2025-11-01T11:46:16.705+0000] {subprocess.py:93} INFO -         toLowCardinality(card_type)  as card_type,
[2025-11-01T11:46:16.706+0000] {subprocess.py:93} INFO -         reference,
[2025-11-01T11:46:16.708+0000] {subprocess.py:93} INFO -         order_reference,
[2025-11-01T11:46:16.709+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.709+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.710+0000] {subprocess.py:93} INFO -         -- Normalize timestamps to string first
[2025-11-01T11:46:16.711+0000] {subprocess.py:93} INFO -         case
[2025-11-01T11:46:16.711+0000] {subprocess.py:93} INFO -             when toTypeName(created_at) like 'String%' then replaceRegexpAll(created_at, '\\s+UTC$', '')
[2025-11-01T11:46:16.712+0000] {subprocess.py:93} INFO -             else toString(created_at)
[2025-11-01T11:46:16.712+0000] {subprocess.py:93} INFO -         end as created_at_str,
[2025-11-01T11:46:16.713+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.713+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.714+0000] {subprocess.py:93} INFO -         case
[2025-11-01T11:46:16.715+0000] {subprocess.py:93} INFO -             when toTypeName(updated_at) like 'String%' then replaceRegexpAll(updated_at, '\\s+UTC$', '')
[2025-11-01T11:46:16.715+0000] {subprocess.py:93} INFO -             else toString(updated_at)
[2025-11-01T11:46:16.716+0000] {subprocess.py:93} INFO -         end as updated_at_str
[2025-11-01T11:46:16.716+0000] {subprocess.py:93} INFO -     from `bronze`.`payments`
[2025-11-01T11:46:16.717+0000] {subprocess.py:93} INFO - ),
[2025-11-01T11:46:16.717+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.718+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.719+0000] {subprocess.py:93} INFO - src as (
[2025-11-01T11:46:16.719+0000] {subprocess.py:93} INFO -     select
[2025-11-01T11:46:16.720+0000] {subprocess.py:93} INFO -         payment_id,
[2025-11-01T11:46:16.720+0000] {subprocess.py:93} INFO -         merchant_id,
[2025-11-01T11:46:16.721+0000] {subprocess.py:93} INFO -         acquirer_id,
[2025-11-01T11:46:16.722+0000] {subprocess.py:93} INFO -         state,
[2025-11-01T11:46:16.725+0000] {subprocess.py:93} INFO -         card_type,
[2025-11-01T11:46:16.726+0000] {subprocess.py:93} INFO -         reference,
[2025-11-01T11:46:16.727+0000] {subprocess.py:93} INFO -         order_reference,
[2025-11-01T11:46:16.727+0000] {subprocess.py:93} INFO -         parseDateTime64BestEffortOrNull(created_at_str, 6, 'UTC') as created_at,
[2025-11-01T11:46:16.728+0000] {subprocess.py:93} INFO -         parseDateTime64BestEffortOrNull(updated_at_str, 6, 'UTC') as updated_at
[2025-11-01T11:46:16.728+0000] {subprocess.py:93} INFO -     from raw
[2025-11-01T11:46:16.729+0000] {subprocess.py:93} INFO - ),
[2025-11-01T11:46:16.730+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.730+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.731+0000] {subprocess.py:93} INFO - ranked as (
[2025-11-01T11:46:16.731+0000] {subprocess.py:93} INFO -     select
[2025-11-01T11:46:16.732+0000] {subprocess.py:93} INFO -         *,
[2025-11-01T11:46:16.732+0000] {subprocess.py:93} INFO -         row_number() over (
[2025-11-01T11:46:16.733+0000] {subprocess.py:93} INFO -             partition by payment_id
[2025-11-01T11:46:16.733+0000] {subprocess.py:93} INFO -             order by
[2025-11-01T11:46:16.734+0000] {subprocess.py:93} INFO -                 coalesce(updated_at, toDateTime64('1970-01-01 00:00:00', 6, 'UTC')) desc,
[2025-11-01T11:46:16.735+0000] {subprocess.py:93} INFO -                 coalesce(created_at, toDateTime64('1970-01-01 00:00:00', 6, 'UTC')) desc
[2025-11-01T11:46:16.735+0000] {subprocess.py:93} INFO -         ) as rn
[2025-11-01T11:46:16.735+0000] {subprocess.py:93} INFO -     from src
[2025-11-01T11:46:16.736+0000] {subprocess.py:93} INFO - )
[2025-11-01T11:46:16.736+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.737+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:16.737+0000] {subprocess.py:93} INFO - select
[2025-11-01T11:46:16.738+0000] {subprocess.py:93} INFO -     payment_id,
[2025-11-01T11:46:16.739+0000] {subprocess.py:93} INFO -     merchant_id,
[2025-11-01T11:46:16.739+0000] {subprocess.py:93} INFO -     acquirer_id,
[2025-11-01T11:46:16.740+0000] {subprocess.py:93} INFO -     state,
[2025-11-01T11:46:16.741+0000] {subprocess.py:93} INFO -     card_type,
[2025-11-01T11:46:16.742+0000] {subprocess.py:93} INFO -     reference,
[2025-11-01T11:46:16.742+0000] {subprocess.py:93} INFO -     order_reference,
[2025-11-01T11:46:16.743+0000] {subprocess.py:93} INFO -     created_at,
[2025-11-01T11:46:16.744+0000] {subprocess.py:93} INFO -     updated_at,
[2025-11-01T11:46:16.744+0000] {subprocess.py:93} INFO -     toDate(created_at) as data_date
[2025-11-01T11:46:16.745+0000] {subprocess.py:93} INFO - from ranked
[2025-11-01T11:46:16.745+0000] {subprocess.py:93} INFO - where rn = 1
[2025-11-01T11:46:16.746+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:20.590+0000] {subprocess.py:93} INFO - 11:46:20  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991e97a7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991e9779490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991e9a10e10>]}
[2025-11-01T11:46:20.592+0000] {subprocess.py:93} INFO - 11:46:20  Running with dbt=1.10.13
[2025-11-01T11:46:20.595+0000] {subprocess.py:93} INFO - 11:46:20  running dbt with arguments {'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'quiet': 'False', 'introspect': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'log_path': '/dbt/logs', 'invocation_command': 'dbt --no-use-colors run --profiles-dir /dbt --select silver_payments silver_link_transactions --vars {"ds_lagged": "2025-10-30"} --debug', 'partial_parse': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'log_cache_events': 'False', 'profiles_dir': '/dbt', 'use_experimental_parser': 'False', 'no_print': 'None', 'debug': 'True', 'use_colors': 'False', 'log_format': 'default', 'empty': 'False', 'target_path': 'None', 'warn_error': 'None', 'indirect_selection': 'eager', 'write_json': 'True'}
[2025-11-01T11:46:20.877+0000] {subprocess.py:93} INFO - 11:46:20  Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c2e6c9e7-2bd4-4229-86f3-4fbc35272a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991e94efb10>]}
[2025-11-01T11:46:20.958+0000] {subprocess.py:93} INFO - 11:46:20  Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c2e6c9e7-2bd4-4229-86f3-4fbc35272a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991ea072ed0>]}
[2025-11-01T11:46:20.961+0000] {subprocess.py:93} INFO - 11:46:20  Registered adapter: clickhouse=1.9.5
[2025-11-01T11:46:21.074+0000] {subprocess.py:93} INFO - 11:46:21  checksum: 01367b6dc74f82c3c56a5d9124fd6e2c1ef579c424ecde032d4bb44f43a56825, vars: {'ds_lagged': '2025-10-30'}, profile: , target: , version: 1.10.13
[2025-11-01T11:46:21.377+0000] {subprocess.py:93} INFO - 11:46:21  Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[2025-11-01T11:46:21.378+0000] {subprocess.py:93} INFO - 11:46:21  Partial parsing enabled, no changes found, skipping parsing
[2025-11-01T11:46:21.429+0000] {subprocess.py:93} INFO - 11:46:21  Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c2e6c9e7-2bd4-4229-86f3-4fbc35272a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991e925c290>]}
[2025-11-01T11:46:21.562+0000] {subprocess.py:93} INFO - 11:46:21  Wrote artifact WritableManifest to /dbt/target/manifest.json
[2025-11-01T11:46:21.570+0000] {subprocess.py:93} INFO - 11:46:21  Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[2025-11-01T11:46:21.602+0000] {subprocess.py:93} INFO - 11:46:21  Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c2e6c9e7-2bd4-4229-86f3-4fbc35272a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991e9313350>]}
[2025-11-01T11:46:21.605+0000] {subprocess.py:93} INFO - 11:46:21  Found 3 models, 3 sources, 491 macros
[2025-11-01T11:46:21.608+0000] {subprocess.py:93} INFO - 11:46:21  Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2e6c9e7-2bd4-4229-86f3-4fbc35272a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991e9383990>]}
[2025-11-01T11:46:21.613+0000] {subprocess.py:93} INFO - 11:46:21
[2025-11-01T11:46:21.615+0000] {subprocess.py:93} INFO - 11:46:21  Concurrency: 4 threads (target='dev')
[2025-11-01T11:46:21.617+0000] {subprocess.py:93} INFO - 11:46:21
[2025-11-01T11:46:21.619+0000] {subprocess.py:93} INFO - 11:46:21  Acquiring new clickhouse connection 'master'
[2025-11-01T11:46:21.635+0000] {subprocess.py:93} INFO - 11:46:21  Acquiring new clickhouse connection 'list_'
[2025-11-01T11:46:21.652+0000] {subprocess.py:93} INFO - 11:46:21  Opening a new connection, currently in state init
[2025-11-01T11:46:21.909+0000] {subprocess.py:93} INFO - 11:46:21  dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "ck_project", "target_name": "dev", "connection_name": "list_"} */
[2025-11-01T11:46:21.909+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:21.910+0000] {subprocess.py:93} INFO -     select name from system.databases
[2025-11-01T11:46:21.911+0000] {subprocess.py:93} INFO -   ...
[2025-11-01T11:46:21.916+0000] {subprocess.py:93} INFO - 11:46:21  dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[2025-11-01T11:46:21.948+0000] {subprocess.py:93} INFO - 11:46:21  Re-using an available connection from the pool (formerly list_, now list__silver)
[2025-11-01T11:46:21.964+0000] {subprocess.py:93} INFO - 11:46:21  dbt_clickhouse adapter: On list__silver: /* {"app": "dbt", "dbt_version": "1.10.13", "profile_name": "ck_project", "target_name": "dev", "connection_name": "list__silver"} */
[2025-11-01T11:46:21.965+0000] {subprocess.py:93} INFO - select
[2025-11-01T11:46:21.966+0000] {subprocess.py:93} INFO -       t.name as name,
[2025-11-01T11:46:21.966+0000] {subprocess.py:93} INFO -       t.database as schema,
[2025-11-01T11:46:21.967+0000] {subprocess.py:93} INFO -       multiIf(
[2025-11-01T11:46:21.967+0000] {subprocess.py:93} INFO -         engine in ('MaterializedView', 'View'), 'view',
[2025-11-01T11:46:21.968+0000] {subprocess.py:93} INFO -         engine = 'Dictionary', 'dictionary',
[2025-11-01T11:46:21.968+0000] {subprocess.py:93} INFO -         'table'
[2025-11-01T11:46:21.969+0000] {subprocess.py:93} INFO -       ) as type,
[2025-11-01T11:46:21.969+0000] {subprocess.py:93} INFO -       db.engine as db_engine,0 as is_on_cluster
[2025-11-01T11:46:21.971+0000] {subprocess.py:93} INFO -           from system.tables as t join system.databases as db on t.database = db.name
[2025-11-01T11:46:21.972+0000] {subprocess.py:93} INFO -         where schema = 'silver'
[2025-11-01T11:46:21.972+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:21.973+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:21.974+0000] {subprocess.py:93} INFO -   ...
[2025-11-01T11:46:21.975+0000] {subprocess.py:93} INFO - 11:46:21  dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[2025-11-01T11:46:21.977+0000] {subprocess.py:93} INFO - 11:46:21  Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2e6c9e7-2bd4-4229-86f3-4fbc35272a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991e9624c90>]}
[2025-11-01T11:46:21.986+0000] {subprocess.py:93} INFO - 11:46:21  Began running node model.ck_project.silver_link_transactions
[2025-11-01T11:46:21.987+0000] {subprocess.py:93} INFO - 11:46:21  Began running node model.ck_project.silver_payments
[2025-11-01T11:46:21.989+0000] {subprocess.py:93} INFO - 11:46:21  1 of 2 START sql incremental model `silver`.`silver_link_transactions` ......... [RUN]
[2025-11-01T11:46:21.991+0000] {subprocess.py:93} INFO - 11:46:21  2 of 2 START sql incremental model `silver`.`silver_payments` .................. [RUN]
[2025-11-01T11:46:21.993+0000] {subprocess.py:93} INFO - 11:46:21  Re-using an available connection from the pool (formerly list__silver, now model.ck_project.silver_link_transactions)
[2025-11-01T11:46:21.997+0000] {subprocess.py:93} INFO - 11:46:21  Acquiring new clickhouse connection 'model.ck_project.silver_payments'
[2025-11-01T11:46:21.999+0000] {subprocess.py:93} INFO - 11:46:21  Began compiling node model.ck_project.silver_link_transactions
[2025-11-01T11:46:22.006+0000] {subprocess.py:93} INFO - 11:46:21  Began compiling node model.ck_project.silver_payments
[2025-11-01T11:46:22.021+0000] {subprocess.py:93} INFO - 11:46:22  Writing injected SQL for node "model.ck_project.silver_link_transactions"
[2025-11-01T11:46:22.028+0000] {subprocess.py:93} INFO - 11:46:22  Writing injected SQL for node "model.ck_project.silver_payments"
[2025-11-01T11:46:22.045+0000] {subprocess.py:93} INFO - 11:46:22  Began executing node model.ck_project.silver_link_transactions
[2025-11-01T11:46:22.046+0000] {subprocess.py:93} INFO - 11:46:22  Began executing node model.ck_project.silver_payments
[2025-11-01T11:46:22.302+0000] {subprocess.py:93} INFO - 11:46:22  Compilation Error in model silver_payments (models/silver/silver_payments.sql)
[2025-11-01T11:46:22.303+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-11-01T11:46:22.303+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:22.305+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-11-01T11:46:22.306+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.306+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.307+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-11-01T11:46:22.307+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-11-01T11:46:22.308+0000] {subprocess.py:93} INFO -   > called by model silver_payments (models/silver/silver_payments.sql)
[2025-11-01T11:46:22.309+0000] {subprocess.py:93} INFO - 11:46:22  Compilation Error in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-11-01T11:46:22.309+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-11-01T11:46:22.310+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:22.310+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-11-01T11:46:22.311+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.311+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.317+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-11-01T11:46:22.318+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-11-01T11:46:22.318+0000] {subprocess.py:93} INFO -   > called by model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-11-01T11:46:22.319+0000] {subprocess.py:93} INFO - 11:46:22  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2e6c9e7-2bd4-4229-86f3-4fbc35272a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991ec42c290>]}
[2025-11-01T11:46:22.320+0000] {subprocess.py:93} INFO - 11:46:22  Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2e6c9e7-2bd4-4229-86f3-4fbc35272a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991e9868750>]}
[2025-11-01T11:46:22.320+0000] {subprocess.py:93} INFO - 11:46:22  2 of 2 ERROR creating sql incremental model `silver`.`silver_payments` ......... [ERROR in 0.31s]
[2025-11-01T11:46:22.321+0000] {subprocess.py:93} INFO - 11:46:22  1 of 2 ERROR creating sql incremental model `silver`.`silver_link_transactions`  [ERROR in 0.32s]
[2025-11-01T11:46:22.324+0000] {subprocess.py:93} INFO - 11:46:22  Finished running node model.ck_project.silver_payments
[2025-11-01T11:46:22.327+0000] {subprocess.py:93} INFO - 11:46:22  Finished running node model.ck_project.silver_link_transactions
[2025-11-01T11:46:22.330+0000] {subprocess.py:93} INFO - 11:46:22  Marking all children of 'model.ck_project.silver_payments' to be skipped because of status 'error'.  Reason: Compilation Error in model silver_payments (models/silver/silver_payments.sql)
[2025-11-01T11:46:22.330+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-11-01T11:46:22.331+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:22.331+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-11-01T11:46:22.332+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.333+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.334+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-11-01T11:46:22.334+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-11-01T11:46:22.335+0000] {subprocess.py:93} INFO -   > called by model silver_payments (models/silver/silver_payments.sql).
[2025-11-01T11:46:22.336+0000] {subprocess.py:93} INFO - 11:46:22  Marking all children of 'model.ck_project.silver_link_transactions' to be skipped because of status 'error'.  Reason: Compilation Error in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-11-01T11:46:22.336+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-11-01T11:46:22.337+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:22.337+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-11-01T11:46:22.338+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.338+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.339+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-11-01T11:46:22.340+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-11-01T11:46:22.340+0000] {subprocess.py:93} INFO -   > called by model silver_link_transactions (models/silver/silver_link_transactions.sql).
[2025-11-01T11:46:22.341+0000] {subprocess.py:93} INFO - 11:46:22  Connection 'master' was properly closed.
[2025-11-01T11:46:22.342+0000] {subprocess.py:93} INFO - 11:46:22  Connection 'model.ck_project.silver_link_transactions' was left open.
[2025-11-01T11:46:22.342+0000] {subprocess.py:93} INFO - 11:46:22  On model.ck_project.silver_link_transactions: Close
[2025-11-01T11:46:22.343+0000] {subprocess.py:93} INFO - 11:46:22  Connection 'model.ck_project.silver_payments' was properly closed.
[2025-11-01T11:46:22.346+0000] {subprocess.py:93} INFO - 11:46:22
[2025-11-01T11:46:22.347+0000] {subprocess.py:93} INFO - 11:46:22  Finished running 2 incremental models in 0 hours 0 minutes and 0.73 seconds (0.73s).
[2025-11-01T11:46:22.350+0000] {subprocess.py:93} INFO - 11:46:22  Command end result
[2025-11-01T11:46:22.419+0000] {subprocess.py:93} INFO - 11:46:22  Wrote artifact WritableManifest to /dbt/target/manifest.json
[2025-11-01T11:46:22.438+0000] {subprocess.py:93} INFO - 11:46:22  Wrote artifact SemanticManifest to /dbt/target/semantic_manifest.json
[2025-11-01T11:46:22.460+0000] {subprocess.py:93} INFO - 11:46:22  Wrote artifact RunExecutionResult to /dbt/target/run_results.json
[2025-11-01T11:46:22.462+0000] {subprocess.py:93} INFO - 11:46:22
[2025-11-01T11:46:22.465+0000] {subprocess.py:93} INFO - 11:46:22  Completed with 2 errors, 0 partial successes, and 0 warnings:
[2025-11-01T11:46:22.467+0000] {subprocess.py:93} INFO - 11:46:22
[2025-11-01T11:46:22.470+0000] {subprocess.py:93} INFO - 11:46:22  Failure in model silver_payments (models/silver/silver_payments.sql)
[2025-11-01T11:46:22.475+0000] {subprocess.py:93} INFO - 11:46:22    Compilation Error in model silver_payments (models/silver/silver_payments.sql)
[2025-11-01T11:46:22.478+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-11-01T11:46:22.479+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:22.480+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-11-01T11:46:22.481+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.482+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.483+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-11-01T11:46:22.484+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-11-01T11:46:22.485+0000] {subprocess.py:93} INFO -   > called by model silver_payments (models/silver/silver_payments.sql)
[2025-11-01T11:46:22.486+0000] {subprocess.py:93} INFO - 11:46:22
[2025-11-01T11:46:22.487+0000] {subprocess.py:93} INFO - 11:46:22    compiled code at target/compiled/ck_project/models/silver/silver_payments.sql
[2025-11-01T11:46:22.488+0000] {subprocess.py:93} INFO - 11:46:22
[2025-11-01T11:46:22.489+0000] {subprocess.py:93} INFO - 11:46:22  Failure in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-11-01T11:46:22.489+0000] {subprocess.py:93} INFO - 11:46:22    Compilation Error in model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-11-01T11:46:22.490+0000] {subprocess.py:93} INFO -   macro 'dbt_macro__clickhouse__create_table_as' takes not more than 2 argument(s)
[2025-11-01T11:46:22.491+0000] {subprocess.py:93} INFO - 
[2025-11-01T11:46:22.492+0000] {subprocess.py:93} INFO -   > in macro create_table_as (macros/relations/table/create.sql)
[2025-11-01T11:46:22.492+0000] {subprocess.py:93} INFO -   > called by macro default__get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.493+0000] {subprocess.py:93} INFO -   > called by macro get_create_table_as_sql (macros/relations/table/create.sql)
[2025-11-01T11:46:22.494+0000] {subprocess.py:93} INFO -   > called by macro statement (macros/etc/statement.sql)
[2025-11-01T11:46:22.494+0000] {subprocess.py:93} INFO -   > called by macro materialization_incremental_clickhouse (macros/materializations/incremental/incremental.sql)
[2025-11-01T11:46:22.495+0000] {subprocess.py:93} INFO -   > called by model silver_link_transactions (models/silver/silver_link_transactions.sql)
[2025-11-01T11:46:22.496+0000] {subprocess.py:93} INFO - 11:46:22
[2025-11-01T11:46:22.496+0000] {subprocess.py:93} INFO - 11:46:22    compiled code at target/compiled/ck_project/models/silver/silver_link_transactions.sql
[2025-11-01T11:46:22.497+0000] {subprocess.py:93} INFO - 11:46:22
[2025-11-01T11:46:22.498+0000] {subprocess.py:93} INFO - 11:46:22  Done. PASS=0 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=2
[2025-11-01T11:46:22.500+0000] {subprocess.py:93} INFO - 11:46:22  Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.03461, "process_in_blocks": "0", "process_kernel_time": 0.444007, "process_mem_max_rss": "143604", "process_out_blocks": "0", "process_user_time": 3.394642}
[2025-11-01T11:46:22.502+0000] {subprocess.py:93} INFO - 11:46:22  Command `dbt run` failed at 11:46:22.500464 after 2.04 seconds
[2025-11-01T11:46:22.505+0000] {subprocess.py:93} INFO - 11:46:22  Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991eaa40ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991ee0a1910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7991e30ba450>]}
[2025-11-01T11:46:22.508+0000] {subprocess.py:93} INFO - 11:46:22  Flushing usage events
[2025-11-01T11:46:23.004+0000] {subprocess.py:93} INFO - 11:46:23  An error was encountered while trying to flush usage events
[2025-11-01T11:46:23.484+0000] {subprocess.py:93} INFO - COMPILED: -c: line 26: syntax error: unexpected end of file
[2025-11-01T11:46:23.497+0000] {subprocess.py:97} INFO - Command exited with return code 2
[2025-11-01T11:46:23.514+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2025-11-01T11:46:23.518+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=ingestion_pipeline, task_id=silver_dbt.dbt_run_incrementals, execution_date=20251030T000000, start_date=20251101T114609, end_date=20251101T114623
[2025-11-01T11:46:23.541+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 47 for task silver_dbt.dbt_run_incrementals (Bash command failed. The command returned a non-zero exit code 2.; 1128)
[2025-11-01T11:46:23.570+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-11-01T11:46:23.591+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
